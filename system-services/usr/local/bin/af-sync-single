#!/usr/bin/env python

## Global Variables
AUDIOFILE_DAY_CACHE_STORAGE = '/mnt/audiofile-day-cache/audio'


## Set Defaults
INTER_DELTA_SLEEP_TIME = 750
DELTA_RETRIES = 2
NO_PROGRESS_SLEEP_TIME = 120000
CHUNK_SIZE = 4 * 1024 * 1024
ADMIN_EMAILS = []  # While debugging the script
#ADMIN_EMAILS = ['Ian.Llewellyn@rte.ie', 'radiomnt@rte.ie']


## Local Variables
tgt_fp = None
no_progress_sleep_time = 0
recent_truncations = []


## Import Modules
import urllib2
import time
from datetime import datetime
import os
from sys import exit, argv
import simplejson
import optparse
from socket import gethostname
import logging
import logging.handlers

STDERR_LOG_LEVEL = logging.INFO
LOGFILE_LOG_LEVEL = logging.INFO
EMAIL_LOG_LEVEL = logging.WARNING


## Global Function Definitions
def fetch_delta(req_URI, target_file):
    """ fetch_delta(host, format, service) -> True/False
    Does a HTTP range request to http://host/format/service/date/file
    fetching only the bytes beyond the end of the target_file size.
    """
    global tgt_fp
    if not tgt_fp:
        # Does the directory exist?
        if not os.path.exists(os.path.dirname(target_file)):
            # Create the directory - date_dir most likely
            logger.info('Creating directory: %s'
                        % os.path.dirname(target_file))
            try:
                os.mkdir(os.path.dirname(target_file), 0755)
            except OSError:
                os.makedirs(os.path.dirname(target_file), 0755)

        logger.info('Opening file: %s in append mode' % target_file)
        tgt_fp = open(target_file, 'ab')

    # Move file pointer to the end of the file
    tgt_fp.seek(0, 2)
    # How many bytes have we got already?
    offset = tgt_fp.tell()
    logger.debug('File: %s has size: %d' % (target_file, offset))

    http_req = urllib2.Request(req_URI)
    # Only get updates - THIS IS THE MAGIC
    http_req.headers['Range'] = 'bytes=%s-' % offset

    logger.debug('Requesting: %s' % req_URI)
    try:
        http_resp = urllib2.urlopen(http_req)
    except urllib2.HTTPError, error:
        logger.warning('Received HTTP error: %d - %s'
                       % (error.code, error.reason))
        # We know about only one type of HTTP error we can recover from - A 416
        if error.code != 416:
            logger.exception(1, 'Can\'t handle HTTP error: %d - %s'
                             % (error.code, error.reason))
            raise
        # Certain servers produce
        # HTTP 416: Requested Range Not Satisfiable responses
        data_length = 0
        resp_code = error.code
    except urllib2.URLError, error:
        # If a firewall is blocking access, you get:
        # 113, 'No route to host'
        logger.warning('Received URLError in function: fetch_delta(%s, %s): %s'
                       % (req_URI, target_file, error))
        return False
    else:
        data_length = int(http_resp.headers.getheader('content-length'))
        resp_code = http_resp.code

    # If the file size hasn't changed since the last request, some servers
    # return a 200 response and the full file. Others respond with a HTTP 416
    # error (which is handled in the except above)

    # One of two conditions signify a failed update:
    # 1. We're not at the start of the file and
    #    a partial content response was not recieved
    # 2. No data was received for update
    if (offset != 0 and resp_code != 206) or data_length <= 0:
        logger.info('Delta failure %d: Offset: %d'
                    'HTTP_STATUS_CODE: %d data_length: %d'
                    % (delta_failures + 1, offset, resp_code, data_length))
        return False

    if NO_OP:
        logger.info('Dry run %d: Offset: %d '
                    'HTTP_STATUS_CODE: %d data_length: %d'
                    % (delta_failures + 1, offset, resp_code, data_length))
        return False

    # Write the update and flush to disk
    while True:
        chunk = http_resp.read(CHUNK_SIZE)
        if not chunk:
            break
        tgt_fp.write(chunk)
        tgt_fp.flush()

    logger.debug('Delta success: HTTP_STATUS_CODE: %d data_length: %d'
                 % (resp_code, data_length))
    return True


def get_file_list(host, format, service, date):
    """ get_file_list(host, format, service, date) -> [
        {'title': '01:00:00', 'file': '2012-08-30-00-00-00-00.mp2',
         'size': 123456}*
    ]
    Returns an array from the directory listing received by a HTTP call such
    as: http://host/format/service/date/
    """
    req = urllib2.Request('http://%s/webservice/v2/listfiles.php'
                          '?format=%s&service=%s&date=%s'
                          % (host, format, service, date))
    try:
        resp = urllib2.urlopen(req)
    except urllib2.URLError, error:
        # If a firewall is blocking access, you get: 113, 'No route to host'
        logger.warning('Received URLError in function: '
                       'get_file_list(%s, %s, %s, %s): %s'
                       % (host, format, service, date, error))
        return []
    else:
        decoded = simplejson.loads(resp.read())

    #return record['file'] for record in decoded['files']]
    return decoded['files']


## Local Function Definitions
def usage():
    print '%s -h <host> -s <service> -f <format> [-v] [-n]' % argv[0]
    return


def file_map(src_file):
    """ file_map(src_file) -> target_file
    For a given source file, do a lookup in the map and return the
    relevant target file.
    """
    if not args.map_file:
        return os.path.sep.join(
            [AUDIOFILE_DAY_CACHE_STORAGE, args.format,
             args.service, date, src_file]
        )
    else:
        # calculate the key i.e. local day of week and hour
        dow, hour = utc_file_to_local(src_file)
        # open mapping file
        map_file = open(args.map_file, 'r')
        # read contents into array or such
        for line in map_file.readlines():
            # Ignore comment lines
            if line.startswith('#'):
                continue
            kdow, khour, kfile = line.split()
            if dow == int(kdow) and hour == int(khour):
                # return the corrsponding value
                return kfile
        return None


def utc_file_to_local(file_title):
    """ utc_file_to_local(file_title) -> 2 tuple
    This function takes the time provided in the file name as UTC, converts
    it to local time and returns a tuple with the day-of-week and hour.
    File title should be of the format YYYY-mm-dd-HH-MM-SS-xx.mp2/3.
    """
    # Strip unrequired trailing characters and
    # append UTC to force strptime's hand
    string = file_title.rstrip('0123456789.mp').rstrip('-') + ' UTC'

    # Generate a UTC time tuple
    utc_time = time.strptime(string, '%Y-%m-%d-%H-%M-%S %Z')

    # Convert to a local time tuple - via seconds since the UNIX Epoch
    local_time = time.localtime(time.mktime(utc_time))

    # Extract the bits we want
    dow = time.strftime('%w', local_time)
    hour = local_time.tm_hour

    # Return
    return (int(dow), hour)


# PID / Lockfile


## Parse Command Line Arguments
parser = optparse.OptionParser()

parser.remove_option('-h')

parser.add_option('-h', '--host', dest='host', type=str, nargs=1)
parser.add_option('-f', '--format', dest='format', type=str, nargs=1)
parser.add_option('-s', '--service', dest='service', type=str, nargs=1)
parser.add_option('-d', '--date', dest='date', type=str, nargs=1)
parser.add_option('-m', '--map-file', dest='map_file', type=str, nargs=1)
parser.add_option('-v', '--verbose', dest='verbosity', type=int, nargs=1)
parser.add_option('-n', '--noop', dest='noop', action='store_true',
                  default=False)

args = parser.parse_args()[0]

if args.verbosity:
    STDERR_LOG_LEVEL = args.verbosity

NO_OP = args.noop


## Command Line Argument Sanity Checks
if not args.host or not args.format or not args.service:
    usage()
    exit(os.EX_USAGE)

LOG_FILE = '/var/log/audiofile/af-sync-%s-%s.log' % (args.service, args.format)


## Pre-processing
logger = logging.getLogger('logger')
logger.setLevel(logging.DEBUG)
standard_format = logging.Formatter('[%(asctime)s] '
                                    '%(process)d %(levelname)s: %(message)s')

file_handler = logging.FileHandler(LOG_FILE)
file_handler.setLevel(LOGFILE_LOG_LEVEL)
file_handler.setFormatter(standard_format)
logger.addHandler(file_handler)

stderr_handler = logging.StreamHandler()
stderr_handler.setLevel(STDERR_LOG_LEVEL)
stderr_handler.setFormatter(standard_format)
logger.addHandler(stderr_handler)

#email_handler = logging.handlers.SMTPHandler(
#    'localhost',
#    'AudioFile Rea-Time Sync <af-sync-%s-%s@%s>'
#    % (args.service, args.format, gethostname()),
#    ADMIN_EMAILS, 'Log output from af-sync-%s-%s'
#    % (args.service, args.format)
#)
#
#email_handler.setLevel(EMAIL_LOG_LEVEL)
#email_handler.setFormatter(standard_format)
#logger.addHandler(email_handler)
#
#
## System Integrity Checks
# Bail out early if the target directory doesn't exist.
# Only happens if a map file is not being used.
if not args.map_file and not os.path.exists(AUDIOFILE_DAY_CACHE_STORAGE):
    logger.fatal('AUDIOFILE_DAY_CACHE_STORAGE: %s does not exist'
                 % AUDIOFILE_DAY_CACHE_STORAGE)
    exit(os.EX_OSFILE)


## Print Operating Parameters (outside the loops / on the innermost loop?)


## Processing
try:
    while True:
        # Set today's date !!! UTC
        date = args.date or str(datetime.utcnow().date())

        # Get a list of files for this date from the server
        # and loop through them
        for record in get_file_list(args.host, args.format,
                                    args.service, date):
            # For ease...
            src_file = record['file']
            tgt_file = file_map(src_file)
            if not tgt_file:
                # I can't possibly go on - I have no target!
                logger.warning('file_map returned no target file '
                               'for source file: %s' % src_file)
                continue

            # Reset variable for each file that's encountered
            delta_failures = 0

            # Prepare the file or skip it altogether!
            if(src_file != os.path.basename(tgt_file)
               and tgt_file not in recent_truncations):
                # A map file is being used, empty this file
                # (it hasn't been done in over a day!)
                logger.info('Truncated target file: %s' % tgt_file)
                open(tgt_file, 'w').truncate()
                recent_truncations.append(tgt_file)
                if len(recent_truncations) > 24:
                    recent_truncations.remove(recent_truncations[0])

            elif(os.path.isfile(tgt_file)
                 and record['size'] == os.stat(tgt_file).st_size):
                # Source and target files have the same size,
                # so target is probably fully up-to-date
                logger.info('Target File: %s has same size as Source File: %s'
                            % (tgt_file, src_file))
                continue

            # Work is to be done on this file
            # (only if tgt_file size == 0) ?
            logger.info('Target File: %s started' % tgt_file)
            req_URI = ('http://%s/audio/%s/%s/%s/%s' %
                       (args.host, args.format, args.service, date, src_file))

            while delta_failures <= DELTA_RETRIES:
                while fetch_delta(req_URI, tgt_file):
                    # Successful update - reset failure count and sleep
                    delta_failures = 0
                    no_progress_sleep_time = 0
                    logger.debug('Delta success - About to sleep for %d ms'
                                 % INTER_DELTA_SLEEP_TIME)
                    time.sleep(INTER_DELTA_SLEEP_TIME / 1000.0)

                # Unsuccessful update - mark as a failure and sleep
                delta_failures += 1
                logger.debug('Delta failed %d time(s) '
                             '- About to sleep for %d ms' %
                             (delta_failures, INTER_DELTA_SLEEP_TIME))
                time.sleep(INTER_DELTA_SLEEP_TIME / 1000.0)

            # (at least once an hour - more if errors)
            logger.info('Delta retries: %d exceeded' % DELTA_RETRIES)
            tgt_fp.close()
            tgt_fp = None

        # If a date was passed in, then exit now
        if args.date:
            logger.info('No more updates for date: %s - Exiting' % date)
            exit(os.EX_OK)

        # If no progress is made, we don't want the script going
        # to 100% CPU. Back off..
        if no_progress_sleep_time > NO_PROGRESS_SLEEP_TIME:
            no_progress_sleep_time = NO_PROGRESS_SLEEP_TIME
            logger.warning('no_progress_sleep_time hit max. '
                           'About to sleep for %d ms' % no_progress_sleep_time)
        else:
            logger.info('No progress - About to sleep for %d ms'
                        % no_progress_sleep_time)

        time.sleep(no_progress_sleep_time / 1000)
        no_progress_sleep_time = (no_progress_sleep_time * 2) + 1000
except:
    logger.exception('Caught unhandled exception')
    raise

if __name__ == '__main__':
    pass
